{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV\n",
    "\n",
    "OpenCV is a popular framework for image and video processing. On this tutorial,\n",
    "we show how OpenPifPaf can integrate with a workflow from OpenCV. OpenPifPaf\n",
    "also comes with a video tool for processing videos from files or usb cameras\n",
    "that is based on OpenCV, {ref}`openpifpaf.video <cli-help-video>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import openpifpaf\n",
    "\n",
    "%matplotlib inline\n",
    "openpifpaf.show.Canvas.show = True\n",
    "openpifpaf.show.Canvas.image_min_dpi = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source\n",
    "\n",
    "The `cv2.VideoCapture` class supports an enourmous amount of sources \n",
    "(files, cameras, rtmp, etc, ...) and abstracts the details away. Here, we will\n",
    "just pass in a single image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture('coco/000000081988.jpg')\n",
    "_, image = capture.read()\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with openpifpaf.show.Canvas.image(image) as ax:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "Now that we have the image, we can instantiate an OpenPifPaf network and decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_cpu, _ = openpifpaf.network.Factory(checkpoint='shufflenetv2k16', download_progress=False).factory()\n",
    "decoder = openpifpaf.decoder.factory([hn.meta for hn in net_cpu.head_nets])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can process the image, we need to put it in a dataset that will\n",
    "take care of normalizing the color space and converting the image to a PyTorch \n",
    "tensor that can be processed by a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = openpifpaf.datasets.NumpyImageList([image])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can loop over the images in the dataset, run `decoder.batch()` to\n",
    "obtain human pose predictions for one image and then visualize the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_painter = openpifpaf.show.AnnotationPainter()\n",
    "for image_tensor, _, meta in data:\n",
    "    predictions = decoder.batch(net_cpu, image_tensor.unsqueeze(0))[0]\n",
    "    with openpifpaf.show.Canvas.image(image) as ax:\n",
    "        annotation_painter.annotations(ax, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is intentionally left to be quite basic. If you are interested\n",
    "to accelerate this process with a GPU or you have many images that should be\n",
    "pre-loaded in parallel, please have a look at the {doc}`Prediction API <predict_api>` \n",
    "or use the {ref}`openpifpaf.video <cli-help-video>` command line tool."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('venv3': venv)",
   "metadata": {
    "interpreter": {
     "hash": "ea6946363a43e80d241452ab397f4c58bdd3d2517da174158e9c46ce6717422a"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
