{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FAQ\n",
        "\n",
        "Frequently Asked Questions (FAQ)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why evaluate with 641px instead of 640px?\n",
        "\n",
        "OpenPifPaf uses the standard convention of PyTorch models to pad convolutions. \n",
        "Let's start with an example: a single layer of a 3x3 conv with stride 2 that is padded with 1. For an output feature map of size 2x2, the input must be of size 3x3. This generalization holds: the input must be of size `(nx * stride + 1, ny * stride + 1)`.\n",
        "The models that OpenPifPaf uses have an intermediate layer with stride 16. Therefore, good input image sizes are multiples of 16 plus 1. \n",
        "\n",
        "It is usually not a problem if the input size is not perfect. There will just be a small margin on the right side and bottom of the image that is not \"covered\" by a feature map cell.\n",
        "\n",
        "For more info, see the section on {ref}`coordinate-system`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation Problem\n",
        "\n",
        "This project uses continuous integration testing (CI). That means that a set of \n",
        "unit and integration tests is run on multiple versions of Linux, MacOSX and \n",
        "Windows for every code change. The result of these tests is here: \n",
        "[GitHub Action Tests](https://github.com/vita-epfl/openpifpaf/actions/workflows/tests.yml) \n",
        "and click on the latest test for the main branch to see something like this:\n",
        "\n",
        "![github action test overview](images/githubtests.png)\n",
        "\n",
        "You can click on a build job to see its terminal output. The terminal output \n",
        "shows all steps from cloning the repository, installing PyTorch, installing \n",
        "OpenPifPaf to running linting and the actual tests.\n",
        "If you think the list of platforms and Python versions is outdated and you want \n",
        "a particular combination be added to this list, please file a \n",
        "[GitHub issue](https://github.com/vita-epfl/openpifpaf/issues)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Matplotlib Backend\n",
        "\n",
        "I avoid any plotting on my training servers. However, if you insist on creating plots on the server, you might run into constraints of certain matplotlib backends not being available. If you have a backend that you know is working for your setup, you can select it by prepending any command, for example: `MPLBACKEND=agg python3 -m openpifpaf.train ...`. This would set the backend to `agg` but you can use something else. This works for all Python scripts that use matplotlib.\n",
        "\n",
        "For video on MacOSX, an interactive GUI is required that can update in real-time. I use the matplotlib backend that is called \"macosx\" like this: `MPLBACKEND=macosx python3 -m openpifpaf.video ...`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predict is slow\n",
        "\n",
        "Check whether your installation of PyTorch can access CUDA for GPU processing.\n",
        "If the output of the command below is False, then PyTorch cannot make use of your GPU and OpenPifPaf falls back to CPU processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "python -c \"import torch; print(torch.cuda.is_available())\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can also run `predict` with the `--debug` option. Compare your output with the output in {doc}`predict_cli` to understand which part of the process is slow for you. For a fair comparison, also use `--disable-cuda` because the reference in this documentation is created without CUDA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Python.h or gcc is missing\n",
        "\n",
        "On most systems, you should be able to use a binary wheel (a pre-built binary compilation) so that you don't need to install from source.\n",
        "\n",
        "Source installation might fail with an exception complaining about a missing `Python.h` file or missing `gcc`. This means that you need the development files for Python itself and a C compiler. On Ubuntu systems, you can get this with `sudo apt-get install python3-dev`. For more operating systems, there is a good [StackOverflow post](https://stackoverflow.com/questions/21530577/fatal-error-python-h-no-such-file-or-directory) on the topic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
