{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpifpaf\n",
    "openpifpaf.plugin.register()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "For now, see Method section in our publication for an architecture overview."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Networks\n",
    "\n",
    "The following types of base networks have implementations and can be used with the `--basenet` command line argument for training. Not all base networks are well optimized and you can consult the {ref}`introduction` for benchmark results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(openpifpaf.BASE_FACTORIES.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained Models\n",
    "\n",
    "The current list of pretrained models is below and you can use them with the `--checkpoint` argument. Not all pretrained models are well optimized and you can consult the {ref}`introduction` for benchmark results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[c for c, u in openpifpaf.CHECKPOINT_URLS.items() if isinstance(u, str)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(coordinate-system)=\n",
    "## Coordinate System\n",
    "\n",
    "When adding your own datasets or transformations, it is good to keep in mind the coordinate system that OpenPifPaf assumes. The short summary is, everything is done in such a way that annotation coordinates only need to be multiplied by the image rescaling factor without offset. Therefore, the (0, 0) feature map needs to be aligned with the (0, 0) pixel.\n",
    "\n",
    "![coordinate system](images/coordinate_system.png)\n",
    "\n",
    "This also shows that training image sizes must be a multiple of the network stride _plus one_, i.e., in the above image, an input image size of $5\\times5$ would be optimal for a feature map of size $2\\times2$ because the stride is 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
