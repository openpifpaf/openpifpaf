{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cifar10\n",
    "\n",
    "This plugin is part of `openpifpaf.contrib`. It demonstrates the plugin architecture.\n",
    "There already is a nice dataset for CIFAR10 in `torchvision` and a related [PyTorch tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html). \n",
    "The plugin adds a `DataModule` that uses this dataset.\n",
    "Let's start with them setup for this notebook and registering all available OpenPifPaf plugins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openpifpaf\n",
    "import torchvision\n",
    "\n",
    "%matplotlib inline\n",
    "openpifpaf.show.Canvas.show = True\n",
    "\n",
    "openpifpaf.plugins.register()\n",
    "print(openpifpaf.plugins.REGISTERED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we configure and instantiate the Cifar10 datamodule and look at the configured head metas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure \n",
    "openpifpaf.contrib.cifar10.datamodule.Cifar10.debug = True \n",
    "openpifpaf.contrib.cifar10.datamodule.Cifar10.batch_size = 1\n",
    "\n",
    "# instantiate and inspect\n",
    "datamodule = openpifpaf.contrib.cifar10.datamodule.Cifar10()\n",
    "datamodule.head_metas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that CIFAR10 is being treated as a detection dataset (`CifDet`) and has 10 categories.\n",
    "To create a network, we use the `factory()` function that takes the name of the base network `cifar10net` and the list of head metas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = openpifpaf.network.factory(base_name='cifar10net', head_metas=datamodule.head_metas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the training data that is returned from `datamodule.train_loader()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# configure visualization\n",
    "openpifpaf.visualizer.Base.all_indices = [('cifdet', 9)]  # category 9 = truck\n",
    "openpifpaf.visualizer.CifDet.show_regressions = True\n",
    "\n",
    "# Create a wrapper for a data loader that iterates over a set of matplotlib axes.\n",
    "# The only purpose is to set a different matplotlib axis before each call to \n",
    "# retrieve the next image from the data_loader so that it produces multiple\n",
    "# debug images in one canvas side-by-side.\n",
    "def loop_over_axes(axs, data_loader):\n",
    "    previous_common_ax = openpifpaf.visualizer.Base.common_ax\n",
    "    train_loader_iter = iter(data_loader)\n",
    "    for ax in axs.reshape(-1):\n",
    "        openpifpaf.visualizer.Base.common_ax = ax\n",
    "        yield next(train_loader_iter)\n",
    "    openpifpaf.visualizer.Base.common_ax = previous_common_ax\n",
    "\n",
    "# create a canvas and loop over the first few entries in the training data\n",
    "with openpifpaf.show.canvas(ncols=6, nrows=3, figsize=(10, 5)) as axs:\n",
    "    for images, targets, meta in loop_over_axes(axs, datamodule.train_loader()):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We train a very small network, `cifar10net`, for only one epoch. Afterwards, we will investigate its predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python -m openpifpaf.train --dataset=cifar10 --basenet=cifar10net --epochs=1 --log-interval=500 --lr-warm-up-epochs=0.1 --lr=3e-3 --batch-size=16 --loader-workers=2 --output=cifar10_tutorial.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Training Logs\n",
    "\n",
    "You can create a set of plots from the command line with `python -m openpifpaf.logs cifar10_tutorial.pkl.log`. You can also overlay multiple runs. Below we call the plotting code from that command directly to show the output in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openpifpaf.logs\n",
    "openpifpaf.logs.Plots(['cifar10_tutorial.pkl.log']).show_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "First using CLI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python -m openpifpaf.predict --checkpoint cifar10_tutorial.pkl.epoch001 images/cifar10_*.png --seed-threshold=0.1 --json-output .\n",
    "!cat cifar10_*.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net_cpu, _ = openpifpaf.network.factory(checkpoint='cifar10_tutorial.pkl.epoch001')\n",
    "preprocess = openpifpaf.transforms.Compose([\n",
    "    openpifpaf.transforms.NormalizeAnnotations(),\n",
    "    openpifpaf.transforms.CenterPadTight(16),\n",
    "    openpifpaf.transforms.EVAL_TRANSFORM,\n",
    "])\n",
    "\n",
    "openpifpaf.decoder.utils.CifDetSeeds.threshold = 0.1\n",
    "openpifpaf.decoder.utils.nms.Detection.instance_threshold = 0.1\n",
    "decode = openpifpaf.decoder.factory([hn.meta for hn in net_cpu.head_nets])\n",
    "\n",
    "data = openpifpaf.datasets.ImageList([\n",
    "    'images/cifar10_airplane4.png',\n",
    "    'images/cifar10_automobile10.png',\n",
    "    'images/cifar10_ship7.png',\n",
    "    'images/cifar10_truck8.png',\n",
    "], preprocess=preprocess)\n",
    "for image, _, meta in data:\n",
    "    predictions = decode.batch(net_cpu, image.unsqueeze(0))[0]\n",
    "    print(['{} {:.0%}'.format(pred.category, pred.score) for pred in predictions])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "I selected the above images, because their category is clear to me. There are images in cifar10 where it is more difficult to tell what the category is and so it is probably also more difficult for a neural network.\n",
    "\n",
    "Therefore, we should run a proper quantitative evaluation with `openpifpaf.eval`. It stores its output as a json file, so we print that afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python -m openpifpaf.eval --checkpoint cifar10_tutorial.pkl.epoch001 --dataset=cifar10 --seed-threshold=0.1 --instance-threshold=0.1 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python -m json.tool cifar10_tutorial.pkl.epoch001.eval-cifar10.stats.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that some categories like \"plane\", \"car\" and \"ship\" are learned quickly whereas as others are learned poorly (e.g. \"bird\"). The poor performance is not surprising as we trained our network for a single epoch only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
