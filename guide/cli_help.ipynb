{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLI `--help`\n",
    "\n",
    "This is a reference for all the `--help` message from all of OpenPifPaf's command line interfaces (CLIs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(cli-help-predict)=\n",
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "usage: python3 -m openpifpaf.predict [-h] [--version]\n                                     [--checkpoint CHECKPOINT]\n                                     [--basenet BASENET]\n                                     [--headnets HEADNETS [HEADNETS ...]]\n                                     [--no-pretrain] [--two-scale]\n                                     [--multi-scale] [--no-multi-scale-hflip]\n                                     [--cross-talk CROSS_TALK]\n                                     [--head-dropout HEAD_DROPOUT]\n                                     [--head-quad HEAD_QUAD]\n                                     [--seed-threshold SEED_THRESHOLD]\n                                     [--instance-threshold INSTANCE_THRESHOLD]\n                                     [--keypoint-threshold KEYPOINT_THRESHOLD]\n                                     [--decoder-workers DECODER_WORKERS]\n                                     [--dense-connections]\n                                     [--dense-coupling DENSE_COUPLING]\n                                     [--caf-seeds] [--force-complete-pose]\n                                     [--profile-decoder PROFILE_DECODER]\n                                     [--cif-th CIF_TH] [--caf-th CAF_TH]\n                                     [--connection-method {max,blend}]\n                                     [--greedy] [--show-box]\n                                     [--show-joint-scales]\n                                     [--show-joint-confidences]\n                                     [--show-decoding-order]\n                                     [--show-frontier-order]\n                                     [--show-only-decoded-connections]\n                                     [--debug-cifhr] [--debug-cif-c]\n                                     [--debug-cif-v] [--debug-cifdet-c]\n                                     [--debug-cifdet-v] [--debug-caf-c]\n                                     [--debug-caf-v]\n                                     [--debug-indices DEBUG_INDICES [DEBUG_INDICES ...]]\n                                     [--glob GLOB] [--show]\n                                     [--image-output [IMAGE_OUTPUT [IMAGE_OUTPUT ...]]]\n                                     [--json-output [JSON_OUTPUT [JSON_OUTPUT ...]]]\n                                     [--batch-size BATCH_SIZE]\n                                     [--long-edge LONG_EDGE]\n                                     [--loader-workers LOADER_WORKERS]\n                                     [--disable-cuda]\n                                     [--line-width LINE_WIDTH]\n                                     [--monocolor-connections]\n                                     [--figure-width FIGURE_WIDTH]\n                                     [--dpi-factor DPI_FACTOR] [-q] [--debug]\n                                     [--debug-images]\n                                     [images [images ...]]\n\nPredict poses for given images.\n\npositional arguments:\n  images                input images (default: None)\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --version             show program's version number and exit\n  --glob GLOB           glob expression for input images (for many images)\n                        (default: None)\n  --show                show image of output overlay (default: False)\n  --image-output [IMAGE_OUTPUT [IMAGE_OUTPUT ...]]\n                        image output file or directory (default: None)\n  --json-output [JSON_OUTPUT [JSON_OUTPUT ...]]\n                        json output file or directory (default: None)\n  --batch-size BATCH_SIZE\n                        processing batch size (default: 1)\n  --long-edge LONG_EDGE\n                        apply preprocessing to batch images (default: None)\n  --loader-workers LOADER_WORKERS\n                        number of workers for data loading (default: None)\n  --disable-cuda        disable CUDA (default: False)\n  --line-width LINE_WIDTH\n                        line width for skeleton (default: 6)\n  --monocolor-connections\n  --figure-width FIGURE_WIDTH\n                        figure width (default: 10.0)\n  --dpi-factor DPI_FACTOR\n                        increase dpi of output image by this factor (default:\n                        1.0)\n\nnetwork configuration:\n  --checkpoint CHECKPOINT\n                        Load a model from a checkpoint. Use \"resnet50\",\n                        \"resnet101\" or \"resnet152\" for pretrained OpenPifPaf\n                        models. (default: None)\n  --basenet BASENET     base network, e.g. resnet50 (default: None)\n  --headnets HEADNETS [HEADNETS ...]\n                        head networks (default: None)\n  --no-pretrain         create model without ImageNet pretraining (default:\n                        True)\n  --two-scale           [experimental] (default: False)\n  --multi-scale         [experimental] (default: False)\n  --no-multi-scale-hflip\n                        [experimental] (default: True)\n  --cross-talk CROSS_TALK\n                        [experimental] (default: 0.0)\n\nhead:\n  --head-dropout HEAD_DROPOUT\n                        [experimental] zeroing probability of feature in head\n                        input (default: 0.0)\n  --head-quad HEAD_QUAD\n                        number of times to apply quad (subpixel conv) to heads\n                        (default: 1)\n\ndecoder configuration:\n  --seed-threshold SEED_THRESHOLD\n                        minimum threshold for seeds (default: 0.5)\n  --instance-threshold INSTANCE_THRESHOLD\n                        filter instances by score (default: 0.1)\n  --keypoint-threshold KEYPOINT_THRESHOLD\n                        filter keypoints by score (default: None)\n  --decoder-workers DECODER_WORKERS\n                        number of workers for pose decoding (default: None)\n  --dense-connections   use dense connections (default: False)\n  --dense-coupling DENSE_COUPLING\n                        dense coupling (default: 0.01)\n  --caf-seeds           [experimental] (default: False)\n  --force-complete-pose\n  --profile-decoder PROFILE_DECODER\n                        specify out .prof file or empty string (default: None)\n\nCifCaf decoders:\n  --cif-th CIF_TH       cif threshold (default: 0.1)\n  --caf-th CAF_TH       caf threshold (default: 0.1)\n  --connection-method {max,blend}\n                        connection method to use, max is faster (default:\n                        blend)\n  --greedy              greedy decoding (default: False)\n\nshow:\n  --show-box\n  --show-joint-scales\n  --show-joint-confidences\n  --show-decoding-order\n  --show-frontier-order\n  --show-only-decoded-connections\n\npose visualizer:\n  --debug-cifhr\n  --debug-cif-c\n  --debug-cif-v\n  --debug-cifdet-c\n  --debug-cifdet-v\n  --debug-caf-c\n  --debug-caf-v\n  --debug-indices DEBUG_INDICES [DEBUG_INDICES ...]\n                        indices of fields to create debug plots for of the\n                        form headname:fieldindex, e.g. cif:5 (default: [])\n\nlogging:\n  -q, --quiet           only show warning messages or above (default: False)\n  --debug               print debug messages (default: False)\n  --debug-images        print debug messages and enable all debug images\n                        (default: False)\n"
    }
   ],
   "source": [
    "!python3 -m openpifpaf.predict --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(cli-help-video)=\n",
    "## video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "usage: python3 -m openpifpaf.video [-h] [--version] [--checkpoint CHECKPOINT]\n                                   [--basenet BASENET]\n                                   [--headnets HEADNETS [HEADNETS ...]]\n                                   [--no-pretrain] [--two-scale]\n                                   [--multi-scale] [--no-multi-scale-hflip]\n                                   [--cross-talk CROSS_TALK]\n                                   [--head-dropout HEAD_DROPOUT]\n                                   [--head-quad HEAD_QUAD]\n                                   [--seed-threshold SEED_THRESHOLD]\n                                   [--instance-threshold INSTANCE_THRESHOLD]\n                                   [--keypoint-threshold KEYPOINT_THRESHOLD]\n                                   [--decoder-workers DECODER_WORKERS]\n                                   [--dense-connections]\n                                   [--dense-coupling DENSE_COUPLING]\n                                   [--caf-seeds] [--force-complete-pose]\n                                   [--profile-decoder PROFILE_DECODER]\n                                   [--cif-th CIF_TH] [--caf-th CAF_TH]\n                                   [--connection-method {max,blend}]\n                                   [--greedy] [--show-box]\n                                   [--show-joint-scales]\n                                   [--show-joint-confidences]\n                                   [--show-decoding-order]\n                                   [--show-frontier-order]\n                                   [--show-only-decoded-connections]\n                                   [--debug-cifhr] [--debug-cif-c]\n                                   [--debug-cif-v] [--debug-cifdet-c]\n                                   [--debug-cifdet-v] [--debug-caf-c]\n                                   [--debug-caf-v]\n                                   [--debug-indices DEBUG_INDICES [DEBUG_INDICES ...]]\n                                   [--source SOURCE]\n                                   [--video-output [VIDEO_OUTPUT [VIDEO_OUTPUT ...]]]\n                                   [--video-fps VIDEO_FPS] [--show]\n                                   [--horizontal-flip]\n                                   [--no-colored-connections] [--disable-cuda]\n                                   [--scale SCALE] [--start-frame START_FRAME]\n                                   [--skip-frames SKIP_FRAMES]\n                                   [--max-frames MAX_FRAMES]\n                                   [--json-output [JSON_OUTPUT [JSON_OUTPUT ...]]]\n                                   [-q] [--debug]\n\nVideo demo application.\n\nUse --scale=0.2 to reduce the input image size to 20%.\nUse --json-output for headless processing.\n\nExample commands:\n    python3 -m pifpaf.video --source=0  # default webcam\n    python3 -m pifpaf.video --source=1  # another webcam\n\n    # streaming source\n    python3 -m pifpaf.video --source=http://127.0.0.1:8080/video\n\n\n    python3 -m pifpaf.video --source=docs/coco/000000081988.jpg\n\nTrouble shooting:\n* MacOSX: try to prefix the command with \"MPLBACKEND=MACOSX\".\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --version             show program's version number and exit\n  --source SOURCE       OpenCV source url. Integer for webcams. Supports rtmp\n                        streams. (default: None)\n  --video-output [VIDEO_OUTPUT [VIDEO_OUTPUT ...]]\n                        video output file (default: None)\n  --video-fps VIDEO_FPS\n  --show\n  --horizontal-flip\n  --no-colored-connections\n                        do not use colored connections to draw poses (default:\n                        True)\n  --disable-cuda        disable CUDA (default: False)\n  --scale SCALE         input image scale factor (default: 1.0)\n  --start-frame START_FRAME\n  --skip-frames SKIP_FRAMES\n  --max-frames MAX_FRAMES\n  --json-output [JSON_OUTPUT [JSON_OUTPUT ...]]\n                        json output file (default: None)\n\nnetwork configuration:\n  --checkpoint CHECKPOINT\n                        Load a model from a checkpoint. Use \"resnet50\",\n                        \"resnet101\" or \"resnet152\" for pretrained OpenPifPaf\n                        models. (default: None)\n  --basenet BASENET     base network, e.g. resnet50 (default: None)\n  --headnets HEADNETS [HEADNETS ...]\n                        head networks (default: None)\n  --no-pretrain         create model without ImageNet pretraining (default:\n                        True)\n  --two-scale           [experimental] (default: False)\n  --multi-scale         [experimental] (default: False)\n  --no-multi-scale-hflip\n                        [experimental] (default: True)\n  --cross-talk CROSS_TALK\n                        [experimental] (default: 0.0)\n\nhead:\n  --head-dropout HEAD_DROPOUT\n                        [experimental] zeroing probability of feature in head\n                        input (default: 0.0)\n  --head-quad HEAD_QUAD\n                        number of times to apply quad (subpixel conv) to heads\n                        (default: 1)\n\ndecoder configuration:\n  --seed-threshold SEED_THRESHOLD\n                        minimum threshold for seeds (default: 0.5)\n  --instance-threshold INSTANCE_THRESHOLD\n                        filter instances by score (default: 0.1)\n  --keypoint-threshold KEYPOINT_THRESHOLD\n                        filter keypoints by score (default: None)\n  --decoder-workers DECODER_WORKERS\n                        number of workers for pose decoding (default: None)\n  --dense-connections   use dense connections (default: False)\n  --dense-coupling DENSE_COUPLING\n                        dense coupling (default: 0.01)\n  --caf-seeds           [experimental] (default: False)\n  --force-complete-pose\n  --profile-decoder PROFILE_DECODER\n                        specify out .prof file or empty string (default: None)\n\nCifCaf decoders:\n  --cif-th CIF_TH       cif threshold (default: 0.1)\n  --caf-th CAF_TH       caf threshold (default: 0.1)\n  --connection-method {max,blend}\n                        connection method to use, max is faster (default:\n                        blend)\n  --greedy              greedy decoding (default: False)\n\nshow:\n  --show-box\n  --show-joint-scales\n  --show-joint-confidences\n  --show-decoding-order\n  --show-frontier-order\n  --show-only-decoded-connections\n\npose visualizer:\n  --debug-cifhr\n  --debug-cif-c\n  --debug-cif-v\n  --debug-cifdet-c\n  --debug-cifdet-v\n  --debug-caf-c\n  --debug-caf-v\n  --debug-indices DEBUG_INDICES [DEBUG_INDICES ...]\n                        indices of fields to create debug plots for of the\n                        form headname:fieldindex, e.g. cif:5 (default: [])\n\nlogging:\n  -q, --quiet           only show warning messages or above (default: False)\n  --debug               print debug messages (default: False)\n"
    }
   ],
   "source": [
    "!python3 -m openpifpaf.video --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "usage: python3 -m openpifpaf.train [-h] [--version] [--debug]\n                                   [--checkpoint CHECKPOINT]\n                                   [--basenet BASENET]\n                                   [--headnets HEADNETS [HEADNETS ...]]\n                                   [--no-pretrain] [--two-scale]\n                                   [--multi-scale] [--no-multi-scale-hflip]\n                                   [--cross-talk CROSS_TALK]\n                                   [--head-dropout HEAD_DROPOUT]\n                                   [--head-quad HEAD_QUAD]\n                                   [--lambdas LAMBDAS [LAMBDAS ...]]\n                                   [--r-smooth R_SMOOTH]\n                                   [--regression-loss {smoothl1,smootherl1,l1,laplace}]\n                                   [--background-weight BACKGROUND_WEIGHT]\n                                   [--focal-gamma FOCAL_GAMMA] [--margin-loss]\n                                   [--auto-tune-mtl]\n                                   [--task-sparsity-weight TASK_SPARSITY_WEIGHT]\n                                   [--cif-side-length CIF_SIDE_LENGTH]\n                                   [--caf-min-size CAF_MIN_SIZE]\n                                   [--caf-fixed-size]\n                                   [--caf-aspect-ratio CAF_ASPECT_RATIO]\n                                   [--momentum MOMENTUM] [--beta2 BETA2]\n                                   [--adam-eps ADAM_EPS] [--no-nesterov]\n                                   [--weight-decay WEIGHT_DECAY] [--adam]\n                                   [--amsgrad] [--lr LR]\n                                   [--lr-decay LR_DECAY [LR_DECAY ...]]\n                                   [--lr-decay-factor LR_DECAY_FACTOR]\n                                   [--lr-decay-epochs LR_DECAY_EPOCHS]\n                                   [--lr-warm-up-start-epoch LR_WARM_UP_START_EPOCH]\n                                   [--lr-warm-up-epochs LR_WARM_UP_EPOCHS]\n                                   [--lr-warm-up-factor LR_WARM_UP_FACTOR]\n                                   [--cocokp-train-annotations COCOKP_TRAIN_ANNOTATIONS]\n                                   [--cocodet-train-annotations COCODET_TRAIN_ANNOTATIONS]\n                                   [--cocokp-val-annotations COCOKP_VAL_ANNOTATIONS]\n                                   [--cocodet-val-annotations COCODET_VAL_ANNOTATIONS]\n                                   [--coco-train-image-dir COCO_TRAIN_IMAGE_DIR]\n                                   [--coco-val-image-dir COCO_VAL_IMAGE_DIR]\n                                   [--dataset DATASET] [--n-images N_IMAGES]\n                                   [--duplicate-data DUPLICATE_DATA]\n                                   [--loader-workers LOADER_WORKERS]\n                                   [--batch-size BATCH_SIZE]\n                                   [--square-edge SQUARE_EDGE]\n                                   [--extended-scale]\n                                   [--orientation-invariant ORIENTATION_INVARIANT]\n                                   [--no-augmentation] [--debug-cifhr]\n                                   [--debug-cif-c] [--debug-cif-v]\n                                   [--debug-cifdet-c] [--debug-cifdet-v]\n                                   [--debug-caf-c] [--debug-caf-v]\n                                   [--debug-indices DEBUG_INDICES [DEBUG_INDICES ...]]\n                                   [-o OUTPUT] [--stride-apply STRIDE_APPLY]\n                                   [--epochs EPOCHS]\n                                   [--rescale-images RESCALE_IMAGES]\n                                   [--update-batchnorm-runningstatistics]\n                                   [--ema EMA] [--disable-cuda]\n                                   [--profile PROFILE] [--log-stats]\n                                   [--debug-images]\n\nTrain a pifpaf network.\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --version             show program's version number and exit\n  -o OUTPUT, --output OUTPUT\n                        output file (default: None)\n  --stride-apply STRIDE_APPLY\n                        apply and reset gradients every n batches (default: 1)\n  --epochs EPOCHS       number of epochs to train (default: 75)\n  --rescale-images RESCALE_IMAGES\n                        overall image rescale factor (default: 1.0)\n  --update-batchnorm-runningstatistics\n                        update batch norm running statistics (default: False)\n  --ema EMA             ema decay constant (default: 0.001)\n  --disable-cuda        disable CUDA (default: False)\n\nlogging:\n  --debug               print debug messages (default: False)\n\nnetwork configuration:\n  --checkpoint CHECKPOINT\n                        Load a model from a checkpoint. Use \"resnet50\",\n                        \"resnet101\" or \"resnet152\" for pretrained OpenPifPaf\n                        models. (default: None)\n  --basenet BASENET     base network, e.g. resnet50 (default: None)\n  --headnets HEADNETS [HEADNETS ...]\n                        head networks (default: None)\n  --no-pretrain         create model without ImageNet pretraining (default:\n                        True)\n  --two-scale           [experimental] (default: False)\n  --multi-scale         [experimental] (default: False)\n  --no-multi-scale-hflip\n                        [experimental] (default: True)\n  --cross-talk CROSS_TALK\n                        [experimental] (default: 0.0)\n\nhead:\n  --head-dropout HEAD_DROPOUT\n                        [experimental] zeroing probability of feature in head\n                        input (default: 0.0)\n  --head-quad HEAD_QUAD\n                        number of times to apply quad (subpixel conv) to heads\n                        (default: 1)\n\nlosses:\n  --lambdas LAMBDAS [LAMBDAS ...]\n                        prefactor for head losses (default: None)\n  --r-smooth R_SMOOTH   r_{smooth} for SmoothL1 regressions (default: 0.0)\n  --regression-loss {smoothl1,smootherl1,l1,laplace}\n                        type of regression loss (default: laplace)\n  --background-weight BACKGROUND_WEIGHT\n                        BCE weight where ground truth is background (default:\n                        1.0)\n  --focal-gamma FOCAL_GAMMA\n                        when > 0.0, use focal loss with the given gamma\n                        (default: 1.0)\n  --margin-loss         [experimental] (default: False)\n  --auto-tune-mtl       use Kendall's prescription for adjusting the multitask\n                        weight (default: False)\n  --task-sparsity-weight TASK_SPARSITY_WEIGHT\n                        [experimental] (default: 0.0)\n\nCIF encoder:\n  --cif-side-length CIF_SIDE_LENGTH\n                        side length of the CIF field (default: 4)\n\nCAF encoder:\n  --caf-min-size CAF_MIN_SIZE\n                        min side length of the CAF field (default: 3)\n  --caf-fixed-size      fixed caf size (default: False)\n  --caf-aspect-ratio CAF_ASPECT_RATIO\n                        CAF width relative to its length (default: 0.0)\n\noptimizer:\n  --momentum MOMENTUM   SGD momentum, beta1 in Adam (default: 0.9)\n  --beta2 BETA2         beta2 for Adam/AMSGrad (default: 0.999)\n  --adam-eps ADAM_EPS   eps value for Adam/AMSGrad (default: 1e-06)\n  --no-nesterov         do not use Nesterov momentum for SGD update (default:\n                        True)\n  --weight-decay WEIGHT_DECAY\n                        SGD/Adam/AMSGrad weight decay (default: 0.0)\n  --adam                use Adam optimizer (default: False)\n  --amsgrad             use Adam optimizer with AMSGrad option (default:\n                        False)\n\nlearning rate scheduler:\n  --lr LR               learning rate (default: 0.001)\n  --lr-decay LR_DECAY [LR_DECAY ...]\n                        epochs at which to decay the learning rate (default:\n                        [])\n  --lr-decay-factor LR_DECAY_FACTOR\n                        learning rate decay factor (default: 0.1)\n  --lr-decay-epochs LR_DECAY_EPOCHS\n                        learning rate decay duration in epochs (default: 1.0)\n  --lr-warm-up-start-epoch LR_WARM_UP_START_EPOCH\n                        starting epoch for warm-up (default: 0)\n  --lr-warm-up-epochs LR_WARM_UP_EPOCHS\n                        number of epochs at the beginning with lower learning\n                        rate (default: 1)\n  --lr-warm-up-factor LR_WARM_UP_FACTOR\n                        learning pre-factor during warm-up (default: 0.001)\n\ndataset and loader:\n  --cocokp-train-annotations COCOKP_TRAIN_ANNOTATIONS\n  --cocodet-train-annotations COCODET_TRAIN_ANNOTATIONS\n  --cocokp-val-annotations COCOKP_VAL_ANNOTATIONS\n  --cocodet-val-annotations COCODET_VAL_ANNOTATIONS\n  --coco-train-image-dir COCO_TRAIN_IMAGE_DIR\n  --coco-val-image-dir COCO_VAL_IMAGE_DIR\n  --dataset DATASET\n  --n-images N_IMAGES   number of images to sample (default: None)\n  --duplicate-data DUPLICATE_DATA\n                        duplicate data (default: None)\n  --loader-workers LOADER_WORKERS\n                        number of workers for data loading (default: None)\n  --batch-size BATCH_SIZE\n                        batch size (default: 8)\n\naugmentations:\n  --square-edge SQUARE_EDGE\n                        square edge of input images (default: 385)\n  --extended-scale      augment with an extended scale range (default: False)\n  --orientation-invariant ORIENTATION_INVARIANT\n                        augment with random orientations (default: 0.0)\n  --no-augmentation     do not apply data augmentation (default: True)\n\npose visualizer:\n  --debug-cifhr\n  --debug-cif-c\n  --debug-cif-v\n  --debug-cifdet-c\n  --debug-cifdet-v\n  --debug-caf-c\n  --debug-caf-v\n  --debug-indices DEBUG_INDICES [DEBUG_INDICES ...]\n                        indices of fields to create debug plots for of the\n                        form headname:fieldindex, e.g. cif:5 (default: [])\n\ndebug:\n  --profile PROFILE     enables profiling. specify path for chrome tracing\n                        file (default: None)\n  --log-stats           enable stats logging (default: False)\n  --debug-images        print debug messages and enable all debug images\n                        (default: False)\n"
    }
   ],
   "source": [
    "!python3 -m openpifpaf.train --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eval_coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "usage: python3 -m openpifpaf.eval_coco [-h] [--version]\n                                       [--checkpoint CHECKPOINT]\n                                       [--basenet BASENET]\n                                       [--headnets HEADNETS [HEADNETS ...]]\n                                       [--no-pretrain] [--two-scale]\n                                       [--multi-scale]\n                                       [--no-multi-scale-hflip]\n                                       [--cross-talk CROSS_TALK]\n                                       [--head-dropout HEAD_DROPOUT]\n                                       [--head-quad HEAD_QUAD]\n                                       [--seed-threshold SEED_THRESHOLD]\n                                       [--instance-threshold INSTANCE_THRESHOLD]\n                                       [--keypoint-threshold KEYPOINT_THRESHOLD]\n                                       [--decoder-workers DECODER_WORKERS]\n                                       [--dense-connections]\n                                       [--dense-coupling DENSE_COUPLING]\n                                       [--caf-seeds]\n                                       [--no-force-complete-pose]\n                                       [--profile-decoder PROFILE_DECODER]\n                                       [--cif-th CIF_TH] [--caf-th CAF_TH]\n                                       [--connection-method {max,blend}]\n                                       [--greedy] [--show-box]\n                                       [--show-joint-scales]\n                                       [--show-joint-confidences]\n                                       [--show-decoding-order]\n                                       [--show-frontier-order]\n                                       [--show-only-decoded-connections]\n                                       [--debug-cifhr] [--debug-cif-c]\n                                       [--debug-cif-v] [--debug-cifdet-c]\n                                       [--debug-cifdet-v] [--debug-caf-c]\n                                       [--debug-caf-v]\n                                       [--debug-indices DEBUG_INDICES [DEBUG_INDICES ...]]\n                                       [--output OUTPUT]\n                                       [--detection-annotations] [-n N]\n                                       [--skip-n SKIP_N]\n                                       [--dataset {val,test,test-dev}]\n                                       [--min-ann MIN_ANN]\n                                       [--batch-size BATCH_SIZE]\n                                       [--long-edge LONG_EDGE]\n                                       [--loader-workers LOADER_WORKERS]\n                                       [--orientation-invariant]\n                                       [--extended-scale] [--skip-existing]\n                                       [--disable-cuda] [--write-predictions]\n                                       [--all-images] [--debug]\n                                       [--debug-images] [--log-stats]\n\nEvaluation on COCO data.\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --version             show program's version number and exit\n  --output OUTPUT       output filename without file extension (default: None)\n  --detection-annotations\n  -n N                  number of batches (default: 0)\n  --skip-n SKIP_N       skip n batches (default: 0)\n  --dataset {val,test,test-dev}\n                        dataset to evaluate (default: val)\n  --min-ann MIN_ANN     minimum number of truth annotations (default: 0)\n  --batch-size BATCH_SIZE\n                        batch size (default: 1)\n  --long-edge LONG_EDGE\n                        long edge of input images. Setting to zero deactivates\n                        scaling. (default: 641)\n  --loader-workers LOADER_WORKERS\n                        number of workers for data loading (default: None)\n  --orientation-invariant\n  --extended-scale\n  --skip-existing       skip if output eval file exists already (default:\n                        False)\n  --disable-cuda        disable CUDA (default: False)\n  --write-predictions   write a json and a zip file of the predictions\n                        (default: False)\n  --all-images          run over all images irrespective of catIds (default:\n                        False)\n\nnetwork configuration:\n  --checkpoint CHECKPOINT\n                        Load a model from a checkpoint. Use \"resnet50\",\n                        \"resnet101\" or \"resnet152\" for pretrained OpenPifPaf\n                        models. (default: None)\n  --basenet BASENET     base network, e.g. resnet50 (default: None)\n  --headnets HEADNETS [HEADNETS ...]\n                        head networks (default: None)\n  --no-pretrain         create model without ImageNet pretraining (default:\n                        True)\n  --two-scale           [experimental] (default: False)\n  --multi-scale         [experimental] (default: False)\n  --no-multi-scale-hflip\n                        [experimental] (default: True)\n  --cross-talk CROSS_TALK\n                        [experimental] (default: 0.0)\n\nhead:\n  --head-dropout HEAD_DROPOUT\n                        [experimental] zeroing probability of feature in head\n                        input (default: 0.0)\n  --head-quad HEAD_QUAD\n                        number of times to apply quad (subpixel conv) to heads\n                        (default: 1)\n\ndecoder configuration:\n  --seed-threshold SEED_THRESHOLD\n                        minimum threshold for seeds (default: 0.2)\n  --instance-threshold INSTANCE_THRESHOLD\n                        filter instances by score (default: 0.0)\n  --keypoint-threshold KEYPOINT_THRESHOLD\n                        filter keypoints by score (default: None)\n  --decoder-workers DECODER_WORKERS\n                        number of workers for pose decoding (default: None)\n  --dense-connections   use dense connections (default: False)\n  --dense-coupling DENSE_COUPLING\n                        dense coupling (default: 0.01)\n  --caf-seeds           [experimental] (default: False)\n  --no-force-complete-pose\n  --profile-decoder PROFILE_DECODER\n                        specify out .prof file or empty string (default: None)\n\nCifCaf decoders:\n  --cif-th CIF_TH       cif threshold (default: 0.1)\n  --caf-th CAF_TH       caf threshold (default: 0.1)\n  --connection-method {max,blend}\n                        connection method to use, max is faster (default:\n                        blend)\n  --greedy              greedy decoding (default: False)\n\nshow:\n  --show-box\n  --show-joint-scales\n  --show-joint-confidences\n  --show-decoding-order\n  --show-frontier-order\n  --show-only-decoded-connections\n\npose visualizer:\n  --debug-cifhr\n  --debug-cif-c\n  --debug-cif-v\n  --debug-cifdet-c\n  --debug-cifdet-v\n  --debug-caf-c\n  --debug-caf-v\n  --debug-indices DEBUG_INDICES [DEBUG_INDICES ...]\n                        indices of fields to create debug plots for of the\n                        form headname:fieldindex, e.g. cif:5 (default: [])\n\nlogging:\n  --debug               print debug messages (default: False)\n  --debug-images        print debug messages and enable all debug images\n                        (default: False)\n  --log-stats           enable stats logging (default: False)\n"
    }
   ],
   "source": [
    "!python3 -m openpifpaf.eval_coco --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## export_onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "usage: python3 -m openpifpaf.export_onnx [-h] [--version]\n                                         [--checkpoint CHECKPOINT]\n                                         [--outfile OUTFILE] [--simplify]\n                                         [--polish] [--optimize] [--check]\n\nExport a checkpoint as an ONNX model.\n\nApplies onnx utilities to improve the exported model and\nalso tries to simplify the model with onnx-simplifier.\n\nhttps://github.com/onnx/onnx/blob/master/docs/PythonAPIOverview.md\nhttps://github.com/daquexian/onnx-simplifier\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --version             show program's version number and exit\n  --checkpoint CHECKPOINT\n  --outfile OUTFILE\n  --simplify\n  --polish              runs checker, optimizer and shape inference (default:\n                        False)\n  --optimize\n  --check\n"
    }
   ],
   "source": [
    "!python3 -m openpifpaf.export_onnx --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "usage: python3 -m openpifpaf.benchmark [-h] [--version] [--output OUTPUT]\n                                       [--backbones BACKBONES [BACKBONES ...]]\n                                       [--iccv2019-ablation]\n                                       [--dense-ablation] [--debug]\n\nBenchmark.\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --version             show program's version number and exit\n  --output OUTPUT       output file name (default: None)\n  --backbones BACKBONES [BACKBONES ...]\n                        backbones to evaluate (default: ['shufflenetv2x2',\n                        'resnet50', 'resnet101', 'resnet152'])\n  --iccv2019-ablation\n  --dense-ablation\n\nlogging:\n  --debug               print debug messages (default: False)\n"
    }
   ],
   "source": [
    "!python3 -m openpifpaf.benchmark --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "usage: python3 -m openpifpaf.logs [-h] [--version] [--label LABEL [LABEL ...]]\n                                  [--eval-edge EVAL_EDGE] [--no-share-y]\n                                  [-o OUTPUT] [--show-mtl-sigmas]\n                                  log_file [log_file ...]\n\nConfiguring and visualizing log files.\n\npositional arguments:\n  log_file              path to log file\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --version             show program's version number and exit\n  --label LABEL [LABEL ...]\n                        labels in the same order as files (default: None)\n  --eval-edge EVAL_EDGE\n                        side length during eval (default: 593)\n  --no-share-y          dont share y access (default: True)\n  -o OUTPUT, --output OUTPUT\n                        output prefix (default is log_file + .) (default:\n                        None)\n  --show-mtl-sigmas\n"
    }
   ],
   "source": [
    "!python3 -m openpifpaf.logs --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitvenv3venve864f70b47a24f709eace0523e013bb0",
   "display_name": "Python 3.7.4 64-bit ('venv3': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}